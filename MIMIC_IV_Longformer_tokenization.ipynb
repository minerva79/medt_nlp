{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the pickle file into a pandas DataFrame\n",
    "sampled_df = pd.read_pickle(\"mimic_iv_sampled_df.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  name unit admission date discharge date date b...   \n",
      "1  name unit admission date discharge date date b...   \n",
      "2  name unit admission date discharge date date b...   \n",
      "3  name unit admission date discharge date date b...   \n",
      "4  name unit admission date discharge date date b...   \n",
      "\n",
      "                normalized_diseases                                 y  \\\n",
      "0                    [hypertension]                    [hypertension]   \n",
      "1  [atrial fibrillation, pneumonia]  [pneumonia, atrial fibrillation]   \n",
      "2                          [anemia]                          [anemia]   \n",
      "3             [atrial fibrillation]             [atrial fibrillation]   \n",
      "4         [pneumonia, hypertension]         [pneumonia, hypertension]   \n",
      "\n",
      "                         y_joined  \n",
      "0                    hypertension  \n",
      "1  pneumonia, atrial fibrillation  \n",
      "2                          anemia  \n",
      "3             atrial fibrillation  \n",
      "4         pneumonia, hypertension  \n"
     ]
    }
   ],
   "source": [
    "print(sampled_df.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum word count: 186\n",
      "Average word count: 1312.3585833333334\n",
      "Maximum word count: 5678\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming sampled_df is your DataFrame\n",
    "\n",
    "# Counting words in each row\n",
    "sampled_df['word_count'] = sampled_df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Calculating min, avg, and max\n",
    "min_word_count = sampled_df['word_count'].min()\n",
    "avg_word_count = sampled_df['word_count'].mean()\n",
    "max_word_count = sampled_df['word_count'].max()\n",
    "\n",
    "print(f\"Minimum word count: {min_word_count}\")\n",
    "print(f\"Average word count: {avg_word_count}\")\n",
    "print(f\"Maximum word count: {max_word_count}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05     684.00\n",
      "0.20     930.00\n",
      "0.30    1036.00\n",
      "0.40    1135.00\n",
      "0.50    1241.00\n",
      "0.60    1351.00\n",
      "0.70    1472.00\n",
      "0.80    1636.00\n",
      "0.95    2160.05\n",
      "Name: word_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming sampled_df is your DataFrame and it already has the 'word_count' column\n",
    "\n",
    "# Calculate quantiles from 0.1 to 0.9\n",
    "quantiles = sampled_df['word_count'].quantile([0.05, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.95])\n",
    "\n",
    "print(quantiles)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "one_hot_encoded_data = mlb.fit_transform(sampled_df['y'])\n",
    "one_hot_encoded_df = pd.DataFrame(one_hot_encoded_data, columns=mlb.classes_)\n",
    "\n",
    "print(one_hot_encoded_df.shape)\n",
    "print(one_hot_encoded_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import LongformerTokenizer\n",
    "import torch\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "def longformer_tokenize(document, max_length=4096):\n",
    "    return tokenizer(document, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "combined_df['input_ids'] = combined_df['text'].apply(lambda x: longformer_tokenize(x)['input_ids'].squeeze(0))\n",
    "combined_df['attention_mask'] = combined_df['text'].apply(lambda x: longformer_tokenize(x)['attention_mask'].squeeze(0))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save combined_df to a pickle file\n",
    "combined_df.to_pickle(\"combined_df.pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
